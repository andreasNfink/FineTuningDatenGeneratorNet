# FineTuning Data Generator

Eine .NET 8 Bibliothek und Konsolenanwendung zum Erstellen von Finetuning-Daten. Das System bereinigt GitBook Markdown-Dateien und generiert automatisch Frage-Antwort-Paare fÃ¼r das Training von LLMs.

## ğŸ¯ Funktionen

### GitBook Markdown Bereinigung
- **GitBook Markdown Bereinigung**: Entfernt GitBook-spezifische Elemente aus Markdown-Dateien
- **Batch-Verarbeitung**: Verarbeitung einzelner Dateien oder ganzer Verzeichnisse
- **Statistiken**: Detaillierte Berichte Ã¼ber entfernte Elemente

### Finetuning-Daten Generierung
- **KI-gestÃ¼tzte Frage-Antwort-Generierung**: Automatische Erstellung von Training-Samples mit LLM
- **Multiple Pipelines**: Anleitungen, Troubleshooting, Anlagenhistorien
- **OpenAI-kompatible Ausgabe**: JSONL-Format fÃ¼r Finetuning
- **Deutsche Sprache**: Optimiert fÃ¼r deutschsprachige technische Dokumentation
- **Intelligente Chunking**: Semantische Aufteilung von Dokumenten
- **Verschiedene Fragetypen**: "Was ist", "Wie funktioniert", "Welche Schritte", etc.

### Interaktive Bedienung
- **Interaktiver Modus**: Benutzerfreundliche Kommandozeileninteraktion
- **LLM-Verbindungstest**: ÃœberprÃ¼fung der API-KonnektivitÃ¤t
- **Konfigurierbare Parameter**: Flexible Anpassung an verschiedene LLMs

## ğŸ§¹ Bereinigte Elemente

Die Anwendung entfernt folgende GitBook-spezifische Elemente:

- `{% hint %}...{% endhint %}` BlÃ¶cke
- `{% include "..." %}` Anweisungen
- `[text](link "mention")` Mentions â†’ `[text]`
- `<mark>` HTML-Tags (behÃ¤lt Inhalt)
- Alle anderen HTML-Tags
- HTML-Entities (`&#x20;`, `&nbsp;`, etc.)
- GitBook Kommentare (`<!-- filepath: ... -->`)
- Mermaid-Diagramme (`\`\`\`mermaid ... \`\`\``)
- Mehrfache Leerzeilen

## ğŸš€ Installation & Verwendung

### Voraussetzungen

- .NET 8.0 SDK oder hÃ¶her

### Build

```bash
# Solution bauen
dotnet build

# Nur die Konsolenanwendung bauen
dotnet build src/FineTuningDataGenerator.Console
```

### Verwendung

#### Interaktiver Modus
```bash
dotnet run --project src/FineTuningDataGenerator.Console
```

Optionen:
1. Einzelne Datei bereinigen
2. Verzeichnis bereinigen  
3. Beispieldateien aus InputFiles bereinigen
4. **Finetuning-Daten aus Anleitungen generieren**
5. **LLM-Verbindung testen**

#### Command-Line Modus

Einzelne Datei bereinigen:
```bash
dotnet run --project src/FineTuningDataGenerator.Console -- "InputFiles/auftrage.md"
```

Ganzes Verzeichnis bereinigen:
```bash
dotnet run --project src/FineTuningDataGenerator.Console -- "InputFiles" "OutputFiles"
```

## ğŸ¤– Finetuning-Pipeline Verwendung

### LLM-Konfiguration
Die Anwendung unterstÃ¼tzt OpenAI-kompatible APIs. Beispielkonfiguration:
- **API-Host**: `http://your-llm-server:port/v1`
- **Model**: Name des zu verwendenden Modells
- **API-Key**: Optional, je nach Server-Konfiguration

### Pipeline-Typen
1. **Instructions Pipeline**: Generiert Frage-Antwort-Paare aus technischen Anleitungen
2. **Troubleshooting Pipeline**: FÃ¼r industrielle Troubleshooting-Wissensdatenbanken (geplant)
3. **Maintenance History Pipeline**: FÃ¼r Anlagenhistorien und ReparaturauftrÃ¤ge (geplant)

### Fragetypen fÃ¼r Anleitungen
- `was_ist`: "Was ist...?" Fragen
- `wie_funktioniert`: "Wie funktioniert...?" Fragen  
- `welche_schritte`: "Welche Schritte...?" Fragen
- `warum`: "Warum...?" Fragen
- `wann_verwendet`: "Wann wird...verwendet?" Fragen
- `welche_vorteile`: "Welche Vorteile...?" Fragen
- `wie_konfiguriert`: "Wie konfiguriert man...?" Fragen
- `was_beachten`: "Was sollte man beachten...?" Fragen

## ğŸ“ Projektstruktur

```
FineTuningDataGenerator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ FineTuningDataGenerator.Core/          # Kernbibliothek
â”‚   â”‚   â”œâ”€â”€ Models/                            # Datenmodelle (TrainingData, LLMConfig, etc.)
â”‚   â”‚   â”œâ”€â”€ Services/                          # Services (GitBookMarkdownCleaner, LLMService, etc.)
â”‚   â”‚   â””â”€â”€ Processors/                        # Pipelines (InstructionsPipeline, etc.)
â”‚   â””â”€â”€ FineTuningDataGenerator.Console/       # Konsolenanwendung
â”œâ”€â”€ InputFiles/                                # Beispiel-Eingabedateien (GitBook Markdown)
â”œâ”€â”€ OutputFiles/                               # Bereinigte Markdown-Dateien
â”œâ”€â”€ TrainingData/                              # Generierte JSONL Finetuning-Dateien
â””â”€â”€ FineTuningDataGenerator.sln               # Solution-Datei
```

## ğŸ”§ Nutzung als Bibliothek

### GitBook Bereinigung
```csharp
using FineTuningDataGenerator.Core.Services;
using FineTuningDataGenerator.Core.Processors;

// Einzelne Bereinigung
var cleaner = new GitBookMarkdownCleaner();
var cleanedContent = cleaner.CleanGitBookMarkdown(originalContent);

// Datei-Verarbeitung
var processor = new GitBookFileProcessor();
var result = await processor.ProcessFileAsync("input.md", "output.md");
```

### Finetuning-Daten Generierung
```csharp
using FineTuningDataGenerator.Core.Models;
using FineTuningDataGenerator.Core.Processors;

// Pipeline konfigurieren
var pipelineConfig = new PipelineConfig
{
    Type = PipelineType.Instructions,
    Language = "de",
    LLMConfig = new LLMConfig
    {
        ApiHost = "http://your-llm:9005/v1",
        Model = "your-model",
        ApiKey = "your-api-key"
    },
    TrainingConfig = new TrainingDataConfig
    {
        MaxSamplesPerChunk = 3,
        QuestionTypes = new[] { "was_ist", "wie_funktioniert" }
    }
};

// Pipeline ausfÃ¼hren
var pipeline = new InstructionsPipeline(pipelineConfig);
var result = await pipeline.ProcessDocumentAsync("cleaned-document.md");

// Als JSONL exportieren
var samples = result.TrainingData.Select(td => new ConversationSample
{
    Messages = new List<Message>
    {
        new() { Role = "system", Content = td.System },
        new() { Role = "user", Content = td.User },
        new() { Role = "assistant", Content = td.Assistant }
    }
}).ToList();

await pipeline.ExportToJsonLAsync(samples, "training_data.jsonl");
```

## ğŸ“Š Beispiel-Output

### GitBook Bereinigung
```
=== FineTuning Data Generator ===
GitBook Markdown Bereinigungstool & Finetuning Pipeline

Verarbeite Verzeichnis: InputFiles
Ausgabe: OutputFiles

=== Verarbeitungsergebnis ===
ğŸ“Š Verarbeitet: 2 Dateien, Erfolgreich: 2, Fehlgeschlagen: 0, Elemente entfernt: 214, Zeit: 0,04s

âœ… Erfolgreich verarbeitete Dateien:
   auftrage.md -> auftrage.md (205 Elemente entfernt)
   strategiemanager.md -> strategiemanager.md (9 Elemente entfernt)

ğŸ‰ Verarbeitung abgeschlossen!
```

### Finetuning-Daten Generierung
```
=== Finetuning-Daten Generierung ===
Verarbeite: auftrage.md
âœ… 9 Samples generiert
Verarbeite: strategiemanager.md  
âœ… 12 Samples generiert

ğŸ‰ Finetuning-Daten erfolgreich generiert!
ğŸ“Š Gesamt: 21 Training-Samples
ğŸ“ Datei: TrainingData/instructions_training_data_20250611_164523.jsonl

=== Beispiel Training-Sample ===
SYSTEM: Sie sind ein hilfreicher Assistent fÃ¼r Instandhaltungsmanagement und technische Anleitungen.
USER: Was ist ein Paledo-Auftrag?
ASSISTANT: Ein Paledo-Auftrag ist ein digitaler Workflow fÃ¼r InstandhaltungsmaÃŸnahmen, der die gesamte Kette von der Erstellung und Einplanung...
```

## ğŸ›  Entwicklung

### Dependencies

- **HtmlAgilityPack**: HTML-Parsing und -bereinigung
- **Markdig**: Markdown-Verarbeitung  
- **Microsoft.Extensions.Hosting**: Dependency Injection und Hosting
- **Microsoft.Extensions.Logging**: Logging-Framework
- **System.Text.Json**: JSON-Serialisierung fÃ¼r JSONL-Output

### Tests ausfÃ¼hren

```bash
# Unit-Tests (falls vorhanden)
dotnet test
```

## ğŸ“ Lizenz

Dieses Projekt steht unter der MIT-Lizenz.

## ğŸ¤ Beitragen

1. Fork des Repositories
2. Feature-Branch erstellen (`git checkout -b feature/amazing-feature`)
3. Ã„nderungen commiten (`git commit -m 'Add amazing feature'`)
4. Branch pushen (`git push origin feature/amazing-feature`)
5. Pull Request erstellen

## ğŸ› Issues

Gefundene Bugs oder Feature-Requests kÃ¶nnen als [GitHub Issues](../../issues) gemeldet werden.
